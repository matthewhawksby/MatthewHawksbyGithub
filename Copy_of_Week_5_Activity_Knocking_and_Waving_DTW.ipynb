{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewhawksby/MatthewHawksbyGithub/blob/main/Copy_of_Week_5_Activity_Knocking_and_Waving_DTW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfl0nWWC9shd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3jc-2o6MpG6"
      },
      "source": [
        "*Credit: This activity was prepared by Taher Ahmadi (former Rosie Lab M.Sc.) and adapted by Dr. Lim*\n",
        "\n",
        "## Pre-Processing Functions\n",
        "\n",
        "The code below can be used to perform pre-processing on your gesture data from the Week 3 Activity. While you can analyze your raw gesture data, some pre-processing (or \"cleaning\") of the data can help you obtain better results.\n",
        "\n",
        "Play around with the different methods of pre-processing and see how it affects your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bwqdPFPXMpG9"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from scipy import signal\n",
        "\n",
        "def date_time_to_elapsed_time(result):\n",
        "    result['time'] = pd.to_datetime(result['time'])\n",
        "    position = result.columns.get_loc('time')\n",
        "    result['time'] =  (result.iloc[1:, position] - result.iat[0, position]).dt.total_seconds()\n",
        "    result['time'].fillna(0, inplace=True)\n",
        "    return result\n",
        "\n",
        "def preprocess(df):\n",
        "    result = df.copy()\n",
        "\n",
        "    ## converting date_time column to float time elpsed\n",
        "    if result['time'].dtype == object:\n",
        "        result = date_time_to_elapsed_time(result)\n",
        "\n",
        "    ## Options to try as pre-processing: Use alt+/ to block un-comment / comment\n",
        "    for feature_name in df.columns:\n",
        "        ## min-max normalization\n",
        "        # max_value = result[feature_name].max()\n",
        "        # min_value = result[feature_name].min()\n",
        "        # result[feature_name] = (result[feature_name]) / (max_value - min_value)\n",
        "\n",
        "        ## cropping first and last 20% of the signal\n",
        "        # cropping_precentage = int(len(result[feature_name])*(2/10))\n",
        "        # result[feature_name] = result[feature_name][cropping_precentage:-cropping_precentage]\n",
        "\n",
        "        ## interpolate missing values\n",
        "        # result[feature_name].interpolate(method='linear', inplace=True)\n",
        "\n",
        "        ## or simply dropp missing values\n",
        "        # result[feature_name].dropna(inplace=True)\n",
        "        pass\n",
        "\n",
        "    ## re-sampling\n",
        "    ## if you want to compare signals of different length you can do this step\n",
        "    # resampled =  signal.resample(result, 100)\n",
        "    # result = pd.DataFrame(resampled, columns=result.columns)\n",
        "\n",
        "    ## setting 'time' column as index\n",
        "    result.set_index('time', inplace=True)\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcJYDS336BpZ"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "Download [gesture_dataset.zip] from Canvas and extract the data folder into the current directory. The dataset contains the class' gestures as follows:\n",
        "\n",
        "./turtle\n",
        "\n",
        "./woof\n",
        "\n",
        "... etc.\n",
        "where each person's folder contains their generated .csv files (knock_a.csv, knock_b.csv... wave_a.csv, wave_b.csv..)\n",
        "\n",
        "*Note: Not all students' gesture data was included in the dataset.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w577viZy-fBP"
      },
      "source": [
        "## to unzip uploaded data.zip in the colab directory use following command:\n",
        "!unzip gesture_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7g76r6qMpHI"
      },
      "source": [
        "from glob import glob\n",
        "# Download data.zip from canvas and extract data folder in the current directory\n",
        "# The file hierarchy is as follows:\n",
        "#  ./turtle\n",
        "#  ./woof\n",
        "# ...\n",
        "# including recording files of each student named as following:\n",
        "# ['knock_a.csv', 'knock_b.csv', 'knock_c.csv', 'knock_d.csv',\n",
        "#  'wave_a.csv', 'wave_b.csv', 'wave_c.csv', 'wave_d.csv']\n",
        "\n",
        "records = glob(\"*/\")\n",
        "\n",
        "# The following code reads the data into a pandas dataframe\n",
        "df = []\n",
        "for i in range(len(records)):\n",
        "    knocks = {}\n",
        "    waves = {}\n",
        "    print(i, records[i])\n",
        "    for ch in ['a', 'b', 'c', 'd']:\n",
        "        try:\n",
        "            knocks[ch] = pd.read_csv(records[i]+'knock_'+ch+'.csv')\n",
        "            knocks[ch] = preprocess(knocks[ch])\n",
        "\n",
        "            waves[ch] = pd.read_csv(records[i]+'wave_'+ch+'.csv')\n",
        "            waves[ch] = preprocess(waves[ch])\n",
        "        except:\n",
        "            print(\"Failed to read folder \", records[i])\n",
        "    df.append({'knock':knocks,\n",
        "               'wave': waves})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P60B0khE7nKu"
      },
      "source": [
        "# Visualizing the Data\n",
        "\n",
        "Play around with the data (set the user folder by modifying i)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2lpbPN0BMpHN"
      },
      "source": [
        "plt.figure()\n",
        "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(18, 16), dpi= 80,)\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.5)\n",
        "\n",
        "# Plotting 8th data record as an example\n",
        "i = 8\n",
        "print(records[i])\n",
        "\n",
        "# df[i] is the ith person's data\n",
        "df[i]['knock']['a'].plot(ax=axes[0, 0])\n",
        "axes[0, 0].set_title('knock A');\n",
        "df[i]['knock']['b'].plot(ax=axes[1, 0])\n",
        "axes[1, 0].set_title('knock B');\n",
        "df[i]['knock']['c'].plot(ax=axes[2, 0])\n",
        "axes[2, 0].set_title('knock C');\n",
        "df[i]['knock']['d'].plot(ax=axes[3, 0])\n",
        "axes[3, 0].set_title('knock D');\n",
        "\n",
        "df[i]['wave']['a'].plot(ax=axes[0, 1])\n",
        "axes[0, 1].set_title('wave A');\n",
        "df[i]['wave']['b'].plot(ax=axes[1, 1])\n",
        "axes[1, 1].set_title('wave B');\n",
        "df[i]['wave']['c'].plot(ax=axes[2, 1])\n",
        "axes[2, 1].set_title('wave C');\n",
        "df[i]['wave']['d'].plot(ax=axes[3, 1])\n",
        "axes[3, 1].set_title('wave D');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LriQSqAMpHj"
      },
      "source": [
        "## Dynamic Time Warping\n",
        "\n",
        "Now that you've loaded the data into a dataframe, compute the DTW distance between various data samples. Use this code to fill in the confusion matrix as described in the Canvas activity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kyF-cxZMpHm"
      },
      "source": [
        "## you may need to run following command (by uncommenting):\n",
        "#!pip install dtw\n",
        "\n",
        "from dtw import dtw,accelerated_dtw\n",
        "\n",
        "#compute DTW distance for person i knocking with audio clip A and B\n",
        "d1 = df[0]['knock']['a'].interpolate().values\n",
        "d2 = df[0]['knock']['b'].interpolate().values\n",
        "d, cost_matrix, acc_cost_matrix, path = accelerated_dtw(d1,d2, dist='euclidean')\n",
        "\n",
        "plt.imshow(acc_cost_matrix.T, origin='lower', cmap='gray', interpolation='nearest')\n",
        "plt.plot(path[0], path[1], 'w')\n",
        "plt.xlabel('person1 knock with clip A')\n",
        "plt.ylabel('person1 knock with clip b')\n",
        "plt.title(f'DTW Minimum Path with minimum distance: {np.round(d,2)}')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "q84uh4g-MpHt"
      },
      "source": [
        "list1 = [(i, j) for i in ['knock', 'wave'] for j in ['a','b','c','d']]\n",
        "list2 = [(i, j) for i in ['knock', 'wave'] for j in ['a','b','c','d']]\n",
        "\n",
        "# comparison of DTW for different combinations of acting with different audio clips of one person\n",
        "# you can compare two different person's data for this part, but you have to be careful with the length of data\n",
        "for (signal1, signal2) in [(i, j) for i in list1 for j in list2]:\n",
        "    print(signal1, signal2)\n",
        "    d1 = df[0][signal1[0]][signal1[1]].interpolate().values\n",
        "    d2 = df[0][signal2[0]][signal2[1]].interpolate().values\n",
        "    d, cost_matrix, acc_cost_matrix, path = accelerated_dtw(d1,d2, dist='euclidean')\n",
        "\n",
        "    plt.imshow(acc_cost_matrix.T, origin='lower', cmap='gray', interpolation='nearest')\n",
        "    plt.plot(path[0], path[1], 'w')\n",
        "    plt.xlabel('person1 '+str(signal1))\n",
        "    plt.ylabel('person1 '+str(signal2))\n",
        "    plt.title(f'DTW Minimum Path with minimum distance: {np.round(d,2)}')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}